# My_PlaNet Pytorch å®ç°

[è®ºæ–‡: Learning Latent Dynamics for Planning from Pixels](https://arxiv.org/abs/1811.04551 "pytorch å¤ç°")

---

## é¡¹ç›®ç®€ä»‹

è¯¥é¡¹ç›®ä¸ºè®ºæ–‡: Learning Latent Dynamics for Planning from Pixels æä¾›äº† pytorch æ¡†æ¶ä¸‹çš„å®ç°ï¼Œä»£ç ç®€å•æ˜“è¯»ï¼Œé…æœ‰è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼Œå¸®åŠ©ä»æ•°å­¦ç†è®ºè½¬åŒ–åˆ°ä»£ç å®ç°ã€‚

- è®­ç»ƒè¿‡ç¨‹
- æ¨¡å‹æ¶æ„ï¼ˆEncoder | Recurent State Space Model | Observation Model | Reward Modelï¼‰
- ELBO çš„è¯¦ç»†æ•°å­¦æ¨å¯¼ï¼ˆæ¯”è®ºæ–‡ä¸­çš„æ¨å¯¼æ›´åŠ è¯¦ç»†ï¼Œä¸”æä¾›äº†å¦ä¸€ä¸ªæ¨å¯¼çš„è§†è§’ï¼Œå¸®åŠ©è¯»è€…ç†è§£å˜åˆ†æ¨å¯¼çš„æœ¬è´¨ï¼‰

---

## æ¨¡å‹æ¶æ„

<img src="./RSSM.png" alt="cheetah run" />

1. Encoder:

   å°†è§‚å¯Ÿåˆ°çš„å›¾åƒç¼–ç åˆ°ä½ç»´ç©ºé—´ï¼Œé™ä½è®¡ç®—å¤æ‚åº¦
2. Recurent State Space Model

   - Prior

     **deterministic state model:**

     $$h_{t+1} = f(h_t, s_t, a_t)$$

     å…¶ä¸­ $f(Â·)$ æ˜¯ `GRU` ç½‘ç»œ

     **Stochastic state model:**

     $$s_{t+1}  \sim p(s_{t+1} | h_{t+1})$$
   - Posteriorï¼ˆéœ€è¦å…ˆéªŒè®¡ç®—å‡ºçš„ deterministic  state æ¥è®¡ç®—åéªŒï¼‰

     $$s_{t+1} \sim q(s_{t+1} | h_{t+1}, o_{t+1})$$
3. Observation Model

   $$o_t \sim p(o_t | h_t, s_t)$$
4. Reward Model

   $$r_t \sim p(r_t | h_t, s_t)$$

---

## é¡¹ç›®ç»“æ„

```text
My_PlaNet/
â”œâ”€â”€ log/                 # è®­ç»ƒæ—¥å¿—ã€æ¨¡å‹æƒé‡
â”œâ”€â”€ train.py             # è®­ç»ƒæ–‡ä»¶
â”œâ”€â”€ test.py              # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ model.py             # æ¨¡å‹ (Encoder RSSM Observation Reward)
â”œâ”€â”€ agent.py             # CEM planner
â”œâ”€â”€ utils.py             # ç»éªŒå›æ”¾æ± ã€å›¾åƒé¢„å¤„ç†ï¼ˆé™ä½ä½æ·±åº¦ï¼‰
â”œâ”€â”€ wrappers.py          # ç¯å¢ƒè£…é¥°å™¨ï¼ˆdm_control -> gymï¼‰
â”œâ”€â”€ viewer.py            # OpenCVImageViewer
â””â”€â”€ video_prediction.py  # ç”Ÿæˆé¢„æµ‹å›¾åƒè§†é¢‘
```

---

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- dm_control==1.0.13
- gym==0.26.2
- opencv-python==4.11.0.86
- numpy==1.21.6
- torch==1.13.1
- mujoco==2.3.7

### å®‰è£…æŒ‡å—

```bash
git clone https://github.com/Jinhsi555/My_PlaNet.git
cd My_PlaNet
pip install -r requirements.txt
```

### åŸºç¡€ç”¨æ³•

#### è®­ç»ƒ

```bash
python train.py
```

#### æµ‹è¯•

```bash
python test.py dir
```

#### ç”Ÿæˆé¢„æµ‹è§†é¢‘

```bash
python video_prediction.py dir
```

---

## è¿›é˜¶é€‰é¡¹

### Linux æœåŠ¡å™¨è¿è¡Œ

`Xvfb`ï¼ˆX Virtual Framebufferï¼‰æ˜¯ä¸€ä¸ªè™šæ‹Ÿçš„XæœåŠ¡å™¨ï¼Œå®ƒå¯ä»¥åœ¨æ²¡æœ‰ç‰©ç†æ˜¾ç¤ºè®¾å¤‡çš„æƒ…å†µä¸‹è¿è¡Œå›¾å½¢åº”ç”¨ç¨‹åºã€‚

```bash
Xvfb :99 -screen 0 1024x768x24 &
export DISPLAY=:99
python video_prediction.py dir
```

### Tensorboard è®­ç»ƒæ—¥å¿—å¯è§†åŒ–

```bash
tensorboard --logdir=log --port=6006
```

å¯åŠ¨åï¼Œä½ å¯ä»¥é€šè¿‡æµè§ˆå™¨è®¿é—®è¿™ä¸ª `TensorBoard` å®ä¾‹ã€‚

## é¢„æµ‹æ•ˆæœ

### cheetah run

<img src="./cheetah run.gif" alt="cheetah run" />

### Reacher Easy

<img src="./reacher easy.gif" alt="reacher easy"/>

ç”±äºè®¾å¤‡ç®—åŠ›å’Œæ—¶é—´æœ‰é™ï¼Œè¿™é‡Œå±•ç¤ºçš„æ•ˆæœæ˜¯åªè¿›è¡Œäº† 600 æ¬¡è®­ç»ƒçš„ç»“æœ

## è¯æ˜

**ELBO è¯æ®ä¸‹ç•Œçš„ä¸¤ç§æ¨å¯¼ï¼š**

å…ˆä» VAE çš„åŸç†å…¥æ‰‹ï¼š

<img src="ELBO1.png" alt="ELBO"/>

å†æ¨å¹¿åˆ°è®ºæ–‡ä¸­çš„ Training Objectiveï¼ˆè¿™é‡Œåªç»™å‡ºäº†ç¬¬ä¸€ç§ï¼Œç¬¬äºŒç§è¯»è€…å¯ä»¥å‚è€ƒ VAE çš„ç¬¬äºŒç§æ–¹æ³•è‡ªè¡Œæ¨å¯¼ï¼‰ï¼š

<img src="ELBO2.png" alt="ELBO"/>
<img src="ELBO_proof.png" alt="ELBO"/>

å®šä¹‰åºåˆ—çš„æ¡ä»¶æ¦‚ç‡å¦‚ä¸‹ï¼š
$$\begin{aligned}
p(o_{1:T}, s_{1:T} | a_{1:T}) &= \prod_{t=1}^T p(s_t | s_{t-1}, a_{t-1}) p(o_t | s_t)\\
q(s_{1:T} | o_{1:T}, a_{1:T}) &= \prod_{t=1}^T q(s_t | o_{\leq t}, a_{<t})
\end{aligned}$$

äºæ˜¯å¯ä»¥å¾—åˆ°è§‚æµ‹åºåˆ—çš„æ¡ä»¶å¯¹æ•°ä¼¼ç„¶ï¼š
$$
\begin{aligned}
\log p(o_{1:T} | a_{1:T}) &= \log \int p(s_{1:T}, o_{1:T} | a_{1:T}) \, ds_{1:T} \\
&= \log \int \prod_{t=1}^T p(s_t | s_{t-1}, a_{t-1}) p(o_t | s_t) ds_{1:T} \\
&= \log \int \prod_{t=2}^T p(s_t | s_{t-1}, a_{t-1})\int p(s_1 | s_{0}, a_{0}) p(o_1 | s_1) ds_1 ds_{2:T} \\
&= \log \int \prod_{t=2}^T p(s_t | s_{t-1}, a_{t-1}) p(o_t | s_t) \mathbb E_{s_1 \sim p(s_1 | a_0)} \left [ p(o_1 | s_1) \right ] ds_{2:T} \\
&\cdots \\
&\triangleq \log \int \mathbb E_{p(s_{1:T} | a_{1:T})} \left [ \prod_{t=1}^T p(o_t | s_t)\right ]
\end{aligned}
$$
ç„¶ååˆ©ç”¨**é‡è¦æ€§æƒé‡**å°†çœŸå®çš„åéªŒåˆ†å¸ƒ $p(s_{1:T} | a_{1:T})$ è½¬åŒ–ä¸º**å˜åˆ†åˆ†å¸ƒ** $q(s_{1:T} | o_{{1:T}}, a_{1:T})$ï¼š
$$
\begin{aligned}
\log p(o_{1:T} | a_{1:T}) &= \log \mathbb E_{q(s_{1:T} | o_{1:T},a_{1:T})}
\left [ \prod_{t=1}^T \frac {p(s_t | s_{t-1}, a_t) }{q(s_t | o_{\leq t}, s_{<t})} \cdot p(o_t | s_t) \right ] \\
\end{aligned}
$$
æ ¹æ® Jensen ä¸ç­‰å¼ï¼Œè‹¥ $\phi$ æ˜¯ä»»ä¸€å‡¸å‡½æ•°ï¼Œåˆ™
$$
\varphi(\mathbb E[X]) \leq \mathbb E[\varphi(X)]
$$
ç”±äº $\log(\cdot)$ æ˜¯å‡¹å‡½æ•°ï¼Œåˆ™
$$
\log(\mathbb E[X]) \ge \mathbb E[\log(X)]
$$

$$
\begin{aligned}
\log p(o_{1:T} | a_{1:T}) &= \log \mathbb E_{q(s_{1:T} | o_{1:T},a_{1:T})}
\left [ \prod_{t=1}^T \frac {p(s_t | s_{t-1}, a_t) }{q(s_t | o_{\leq t}, s_{<t})} \cdot p(o_t | s_t) \right ] \\
&\ge \mathbb E_{q(s_{1:T} | o_{1:T},a_{1:T})} \left [ \log \prod _{t=1} ^T \frac {p(s_t | s_{t-1}, a_t) }{q(s_t | o_{\leq t}, s_{<t})} \cdot p(o_t | s_t)  \right ] \\
&= \mathbb E_{q(s_{1:T} | o_{1:T},a_{1:T})} \left [  \sum_{t=1}^T \log p(o_t | s_t) - \sum _{t=1}^T \log \frac{q(s_t | o_{\leq t}, s_{<t}))}{p(s_t |  s_{t-1}, a_t)} \right ]\\
&= \sum _{t=1} ^T 
\left (
	\mathbb E_{q(s_t | o_t,a_t)} \left [ \log p(o_t | s_t) \right ] 
	+ \mathbb E_{q(s_{t-1:t} | o_{\leq t},a_{<t})} \left [ \log p(s_t | s_{t-1}, a_{t-1}) \right ]
	- \mathbb E_{q(s_t | o_t,a_t)} \left [ \log q(s_t | o_{\leq t}, a_{<t}) \right ] 
\right ) \\
&= \sum _{t=1} ^T
\left (
	\mathbb E_{q(s_t | o_t,a_t)} \left [ \log p(o_t | s_t) \right ] 
	+ \int q(s_{t-1} | o_{\leq t-1},a_{<t-1})
	\left ( \int q(s_{t} | o_{\leq t},a_{<t}) \log p(s_t | s_{t-1}, a_{t-1}) ds_t \right )
	ds_{t-1}
	-\int q(s_t | o_t,a_t) \log q(s_t | o_{\leq t}, a_{<t}) ds
\right ) \\
&= \sum _{t=1} ^T
\left (
	\mathbb E_{q(s_t | o_t,a_t)} \left [ \log p(o_t | s_t) \right ] 
	- \int q(s_{t-1} | o_{\leq t-1},a_{<t-1}) 
		\left ( \int q(s_t | o_t,a_t) \log \frac {q(s_t | o_{\leq t}, a_{<t})}{p(s_t | s_{t-1}, a_{t-1})}ds \right ) ds_{t-1}
\right ) \\
&= \sum _{t=1} ^T
\left (
	\mathbb E_{q(s_t | o_t,a_t)} \left [ \log p(o_t | s_t) \right ] 
	- \int q(s_{t-1} | o_{\leq t-1},a_{<t-1}) 
		\text{KL} \left ( q(s_t | o_{\leq t}, a_{<t}) \parallel p(s_t | s_{t-1}, a_{t-1}) \right )
		ds_{t-1}
\right ) \\
&= \sum _{t=1} ^T
\left (
	\mathbb E_{q(s_t | o_t,a_t)} \left [ \log p(o_t | s_t) \right ] 
	- \mathbb E_{q(s_{t-1} | o_{\leq t-1},a_{<t-1})}
	\left [
		\text{KL} \left [ q(s_t | o_{\leq t}, a_{<t}) \parallel p(s_t | s_{t-1}, a_{t-1}) \right ]
	\right ]
\right ) 
&&\blacksquare
\end{aligned}
$$

## Reference

- [Learning Latent Dynamics for Planning from Pixels](https://arxiv.org/abs/1811.04551)
- [cross32768 PlaNet_PyTorch](https://github.com/cross32768/PlaNet_PyTorch.git "pytorch å¤ç°")
- [Official Implementation](https://github.com/google-research/planet.git "pytorch å¤ç°")

---

## è”ç³»æ–¹å¼

ğŸ“§ è”ç³»é‚®ç®±ï¼šwlb17302889331@163.com